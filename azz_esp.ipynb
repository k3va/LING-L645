{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k3va/LING-L645/blob/main/azz_esp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "If CUDA memory runs out code to be uncommented and run\n",
        "!pip install GPUtil\n",
        "\n",
        "import torch\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "from numba import cuda\n",
        "\n",
        "def free_gpu_cache():\n",
        "    print(\"Initial GPU Usage\")\n",
        "    gpu_usage()                             \n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    cuda.select_device(0)\n",
        "    cuda.close()\n",
        "    cuda.select_device(0)\n",
        "\n",
        "    print(\"GPU Usage after emptying the cache\")\n",
        "    gpu_usage()\n",
        "\n",
        "free_gpu_cache()\n",
        "''' "
      ],
      "metadata": {
        "id": "-wCOtogl9Jnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check GPU run or not\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "!nvidia-smi\n",
        "!nvcc --version"
      ],
      "metadata": {
        "id": "KU8gyt3afLNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beagAGw5t5bK"
      },
      "source": [
        "%%capture\n",
        "# Local installation\n",
        "!git clone https://github.com/speechbrain/speechbrain/\n",
        "%cd /content/speechbrain/\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2xRRTu12y1w"
      },
      "source": [
        "%%capture\n",
        "# For pip installation\n",
        "!pip install speechbrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kZj4OG0t_Hn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "\n",
        "#random sample with dataset OR after master JSON data creation\n",
        "import random\n",
        "sample = random.random()\n",
        "if sample <0.8:\n",
        "    <file is train set>\n",
        "elif 0.8 < sample  < 0.9:\n",
        "    <file is  dev set>\n",
        "else:\n",
        "<file is test set>\n",
        "traindict, devdict, testdict = {}, {}, {}\n",
        "\n",
        "#iterate and add to appropriate dict\n",
        "\"\"\"\n",
        "import glob\n",
        "\n",
        "path = \"/content/drive/MyDrive/Research\"\n",
        "files = glob.glob(path+\"/sample/*.wav\")\n",
        "print(files)"
      ],
      "metadata": {
        "id": "93_D6X-tEyLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "import logging\n",
        "from speechbrain.utils.data_utils import get_all_files, download_file\n",
        "from speechbrain.dataio.dataio import read_audio\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "SAMPLERATE = 16000\n",
        "\n",
        "def prepare_mini_librispeech(\n",
        "    data_folder,\n",
        "    save_json_train,\n",
        "    save_json_valid,\n",
        "    save_json_test,\n",
        "    split_ratio=[80, 10, 10],\n",
        "):\n",
        "\n",
        "    # List files and create manifest from list\n",
        "    logger.info(\n",
        "        f\"Creating {save_json_train}, {save_json_valid}, and {save_json_test}\"\n",
        "    )\n",
        "    extension = [\".wav\"]\n",
        "    wav_list = get_all_files(data_folder, match_and=extension)\n",
        "\n",
        "    # Random split the signal list into train, valid, and test sets.\n",
        "    data_split = split_sets(wav_list, split_ratio)\n",
        "\n",
        "    # Creating json files\n",
        "    create_json(data_split[\"train\"], save_json_train)\n",
        "    create_json(data_split[\"valid\"], save_json_valid)\n",
        "    create_json(data_split[\"test\"], save_json_test)\n",
        "\n",
        "\n",
        "def create_json(wav_list, json_file):\n",
        "    \"\"\"\n",
        "    Creates the json file given a list of wav files.\n",
        "    Arguments\n",
        "    ---------\n",
        "    wav_list : list of str\n",
        "        The list of wav files.\n",
        "    json_file : str\n",
        "        The path of the output json file\n",
        "    \"\"\"\n",
        "    # Processing all the wav files in the list\n",
        "    json_dict = {}\n",
        "    for wav_file in wav_list:\n",
        "\n",
        "        # Reading the signal (to retrieve duration in seconds)\n",
        "        signal = read_audio(wav_file)\n",
        "        duration = signal.shape[0] / SAMPLERATE\n",
        "\n",
        "        # Manipulate path to get relative path and uttid\n",
        "        path_parts = wav_file.split(os.path.sep)\n",
        "        uttid, _ = os.path.splitext(path_parts[-1])             #uttid=name of file, _= file extension\n",
        "        relative_path = os.path.join(\"{data_root}\", *path_parts[-5:])\n",
        "\n",
        "        # Getting speaker-id from utterance-id\n",
        "        spk_id = uttid.split(\"_\")[0]\n",
        "\n",
        "        # Create entry for this utterance\n",
        "        json_dict[uttid] = {\n",
        "            \"wav\": relative_path,\n",
        "            \"length\": duration,\n",
        "            \"spk_id\": spk_id,\n",
        "        }\n",
        "\n",
        "    # Writing the dictionary to the json file\n",
        "    with open(json_file, mode=\"w\") as json_f:\n",
        "        json.dump(json_dict, json_f, indent=2)\n",
        "\n",
        "    logger.info(f\"{json_file} successfully created!\")\n",
        "\n",
        "\n",
        "def split_sets(wav_list, split_ratio):\n",
        "    \"\"\"Randomly splits the wav list into training, validation, and test lists.\n",
        "    Note that a better approach is to make sure that all the classes have the\n",
        "    same proportion of samples (e.g, spk01 should have 80% of samples in\n",
        "    training, 10% validation, 10% test, the same for speaker2 etc.). This\n",
        "    is the approach followed in some recipes such as the Voxceleb one. For\n",
        "    simplicity, we here simply split the full list without necessarily respecting\n",
        "    the split ratio within each class.\n",
        "    Arguments\n",
        "    ---------\n",
        "    wav_lst : list\n",
        "        list of all the signals in the dataset\n",
        "    split_ratio: list\n",
        "        List composed of three integers that sets split ratios for train, valid,\n",
        "        and test sets, respectively. For instance split_ratio=[80, 10, 10] will\n",
        "        assign 80% of the sentences to training, 10% for validation, and 10%\n",
        "        for test.\n",
        "    Returns\n",
        "    ------\n",
        "    dictionary containing train, valid, and test splits.\n",
        "    \"\"\"\n",
        "    # Random shuffle of the list\n",
        "    random.shuffle(wav_list)\n",
        "    tot_split = sum(split_ratio)\n",
        "    tot_snts = len(wav_list)\n",
        "    data_split = {}\n",
        "    splits = [\"train\", \"valid\"]\n",
        "\n",
        "    for i, split in enumerate(splits):\n",
        "        n_snts = int(tot_snts * split_ratio[i] / tot_split)\n",
        "        data_split[split] = wav_list[0:n_snts]\n",
        "        del wav_list[0:n_snts]\n",
        "    data_split[\"test\"] = wav_list\n",
        "\n",
        "    return data_split\n",
        "\n",
        "#prepare_mini_librispeech(path+'/sample', path+'/save_json_train.json', path+'/save_json_valid.json', path+'/save_json_test.json')"
      ],
      "metadata": {
        "id": "3RWf64MPHTqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtMw7x0ybFlI"
      },
      "source": [
        "#Training the prebuilt speechbrain model on our sample data-manifest files\n",
        "%cd /content/drive/MyDrive/Research/training\n",
        "!python train.py train.yaml --number_of_epochs=2 #--device='cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@misc{speechbrain,\n",
        "  title={{SpeechBrain}: A General-Purpose Speech Toolkit},\n",
        "  author={Mirco Ravanelli and Titouan Parcollet and Peter Plantinga and Aku Rouhe and Samuele Cornell and Loren Lugosch and Cem Subakan and Nauman Dawalatabad and Abdelwahab Heba and Jianyuan Zhong and Ju-Chieh Chou and Sung-Lin Yeh and Szu-Wei Fu and Chien-Feng Liao and Elena Rastorgueva and Fran√ßois Grondin and William Aris and Hwidong Na and Yan Gao and Renato De Mori and Yoshua Bengio},\n",
        "  year={2021},\n",
        "  eprint={2106.04624},\n",
        "  archivePrefix={arXiv},\n",
        "  primaryClass={eess.AS},\n",
        "  note={arXiv:2106.04624}\n",
        "}"
      ],
      "metadata": {
        "id": "FqhCzkP3bzon"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}