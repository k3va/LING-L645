{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k3va/LING-L645/blob/main/azz_esp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install GPUtil\n",
        "\n",
        "import torch\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "from numba import cuda\n",
        "\n",
        "def free_gpu_cache():\n",
        "    print(\"Initial GPU Usage\")\n",
        "    gpu_usage()                             \n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    cuda.select_device(0)\n",
        "    cuda.close()\n",
        "    cuda.select_device(0)\n",
        "\n",
        "    print(\"GPU Usage after emptying the cache\")\n",
        "    gpu_usage()\n",
        "\n",
        "free_gpu_cache() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wCOtogl9Jnz",
        "outputId": "297c4975-31a0-434a-fe78-7df61079aed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: GPUtil in /usr/local/lib/python3.8/dist-packages (1.4.0)\n",
            "Initial GPU Usage\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% |  1% |\n",
            "GPU Usage after emptying the cache\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  2% |  1% |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check GPU run or not\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "!nvidia-smi\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU8gyt3afLNe",
        "outputId": "2476bcf5-388d-4707-efba-0eeaf2bde1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tue Dec 13 00:49:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    28W /  70W |    102MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beagAGw5t5bK"
      },
      "source": [
        "%%capture\n",
        "# Local installation\n",
        "!git clone https://github.com/speechbrain/speechbrain/\n",
        "%cd /content/speechbrain/\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2xRRTu12y1w"
      },
      "source": [
        "%%capture\n",
        "# For pip installation\n",
        "!pip install speechbrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kZj4OG0t_Hn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b5c544-798d-464b-f889-505c0910d1b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "\n",
        "#random sample with dataset OR after master JSON data creation\n",
        "import random\n",
        "sample = random.random()\n",
        "if sample <0.8:\n",
        "    <file is train set>\n",
        "elif 0.8 < sample  < 0.9:\n",
        "    <file is  dev set>\n",
        "else:\n",
        "<file is test set>\n",
        "traindict, devdict, testdict = {}, {}, {}\n",
        "\n",
        "#iterate and add to appropriate dict\n",
        "\"\"\"\n",
        "import glob\n",
        "\n",
        "path = \"/content/drive/MyDrive/Research\"\n",
        "files = glob.glob(path+\"/sample/*.wav\")\n",
        "print(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93_D6X-tEyLH",
        "outputId": "09626109-6ba0-4f9c-c44c-301e6ea70d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "import logging\n",
        "from speechbrain.utils.data_utils import get_all_files, download_file\n",
        "from speechbrain.dataio.dataio import read_audio\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "SAMPLERATE = 16000\n",
        "\n",
        "def prepare_mini_librispeech(\n",
        "    data_folder,\n",
        "    save_json_train,\n",
        "    save_json_valid,\n",
        "    save_json_test,\n",
        "    split_ratio=[80, 10, 10],\n",
        "):\n",
        "\n",
        "    # List files and create manifest from list\n",
        "    logger.info(\n",
        "        f\"Creating {save_json_train}, {save_json_valid}, and {save_json_test}\"\n",
        "    )\n",
        "    extension = [\".wav\"]\n",
        "    wav_list = get_all_files(data_folder, match_and=extension)\n",
        "\n",
        "    # Random split the signal list into train, valid, and test sets.\n",
        "    data_split = split_sets(wav_list, split_ratio)\n",
        "\n",
        "    # Creating json files\n",
        "    create_json(data_split[\"train\"], save_json_train)\n",
        "    create_json(data_split[\"valid\"], save_json_valid)\n",
        "    create_json(data_split[\"test\"], save_json_test)\n",
        "\n",
        "\n",
        "def create_json(wav_list, json_file):\n",
        "    \"\"\"\n",
        "    Creates the json file given a list of wav files.\n",
        "    Arguments\n",
        "    ---------\n",
        "    wav_list : list of str\n",
        "        The list of wav files.\n",
        "    json_file : str\n",
        "        The path of the output json file\n",
        "    \"\"\"\n",
        "    # Processing all the wav files in the list\n",
        "    json_dict = {}\n",
        "    for wav_file in wav_list:\n",
        "\n",
        "        # Reading the signal (to retrieve duration in seconds)\n",
        "        signal = read_audio(wav_file)\n",
        "        duration = signal.shape[0] / SAMPLERATE\n",
        "\n",
        "        # Manipulate path to get relative path and uttid\n",
        "        path_parts = wav_file.split(os.path.sep)\n",
        "        uttid, _ = os.path.splitext(path_parts[-1])             #uttid=name of file, _= file extension\n",
        "        relative_path = os.path.join(\"{data_root}\", *path_parts[-5:])\n",
        "\n",
        "        # Getting speaker-id from utterance-id\n",
        "        spk_id = uttid.split(\"_\")[0]\n",
        "\n",
        "        # Create entry for this utterance\n",
        "        json_dict[uttid] = {\n",
        "            \"wav\": relative_path,\n",
        "            \"length\": duration,\n",
        "            \"spk_id\": spk_id,\n",
        "        }\n",
        "\n",
        "    # Writing the dictionary to the json file\n",
        "    with open(json_file, mode=\"w\") as json_f:\n",
        "        json.dump(json_dict, json_f, indent=2)\n",
        "\n",
        "    logger.info(f\"{json_file} successfully created!\")\n",
        "\n",
        "\n",
        "def split_sets(wav_list, split_ratio):\n",
        "    \"\"\"Randomly splits the wav list into training, validation, and test lists.\n",
        "    Note that a better approach is to make sure that all the classes have the\n",
        "    same proportion of samples (e.g, spk01 should have 80% of samples in\n",
        "    training, 10% validation, 10% test, the same for speaker2 etc.). This\n",
        "    is the approach followed in some recipes such as the Voxceleb one. For\n",
        "    simplicity, we here simply split the full list without necessarily respecting\n",
        "    the split ratio within each class.\n",
        "    Arguments\n",
        "    ---------\n",
        "    wav_lst : list\n",
        "        list of all the signals in the dataset\n",
        "    split_ratio: list\n",
        "        List composed of three integers that sets split ratios for train, valid,\n",
        "        and test sets, respectively. For instance split_ratio=[80, 10, 10] will\n",
        "        assign 80% of the sentences to training, 10% for validation, and 10%\n",
        "        for test.\n",
        "    Returns\n",
        "    ------\n",
        "    dictionary containing train, valid, and test splits.\n",
        "    \"\"\"\n",
        "    # Random shuffle of the list\n",
        "    random.shuffle(wav_list)\n",
        "    tot_split = sum(split_ratio)\n",
        "    tot_snts = len(wav_list)\n",
        "    data_split = {}\n",
        "    splits = [\"train\", \"valid\"]\n",
        "\n",
        "    for i, split in enumerate(splits):\n",
        "        n_snts = int(tot_snts * split_ratio[i] / tot_split)\n",
        "        data_split[split] = wav_list[0:n_snts]\n",
        "        del wav_list[0:n_snts]\n",
        "    data_split[\"test\"] = wav_list\n",
        "\n",
        "    return data_split\n",
        "\n",
        "#prepare_mini_librispeech(path+'/sample', path+'/save_json_train.json', path+'/save_json_valid.json', path+'/save_json_test.json')"
      ],
      "metadata": {
        "id": "3RWf64MPHTqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtMw7x0ybFlI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97016752-254d-411b-9c24-f0608ce476b6",
        "collapsed": true
      },
      "source": [
        "#Training the prebuilt speechbrain model on our sample data-manifest files\n",
        "%cd /content/drive/MyDrive/Research/training\n",
        "!python train.py train.yaml --number_of_epochs=2 #--device='cpu'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Research/training\n",
            "./rirs_noises.zip exists. Skipping download\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: ./results/speaker_id/1986\n",
            "my_tools - Creating train.json, valid.json, and test.json\n",
            "my_tools - train.json successfully created!\n",
            "my_tools - valid.json successfully created!\n",
            "my_tools - test.json successfully created!\n",
            "speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 4.5M trainable parameters in SpkIdBrain\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            " 50% 1/2 [00:03<00:03,  3.00s/it, train_loss=-.372]\n",
            "speechbrain.core - Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 327, in <module>\n",
            "    spk_id_brain.fit(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/speechbrain/core.py\", line 1153, in fit\n",
            "    self._fit_train(train_set=train_set, epoch=epoch, enable=enable)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/speechbrain/core.py\", line 1004, in _fit_train\n",
            "    for batch in t:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tqdm/std.py\", line 1195, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 671, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n",
            "    return self.collate_fn(data)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/speechbrain/dataio/batch.py\", line 125, in __init__\n",
            "    padded = PaddedData(*padding_func(values, **padding_kwargs))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/speechbrain/utils/data_utils.py\", line 442, in batch_pad_right\n",
            "    padded, valid_percent = pad_right_to(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/speechbrain/utils/data_utils.py\", line 370, in pad_right_to\n",
            "    assert len(target_shape) == tensor.ndim\n",
            "AssertionError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@misc{speechbrain,\n",
        "  title={{SpeechBrain}: A General-Purpose Speech Toolkit},\n",
        "  author={Mirco Ravanelli and Titouan Parcollet and Peter Plantinga and Aku Rouhe and Samuele Cornell and Loren Lugosch and Cem Subakan and Nauman Dawalatabad and Abdelwahab Heba and Jianyuan Zhong and Ju-Chieh Chou and Sung-Lin Yeh and Szu-Wei Fu and Chien-Feng Liao and Elena Rastorgueva and François Grondin and William Aris and Hwidong Na and Yan Gao and Renato De Mori and Yoshua Bengio},\n",
        "  year={2021},\n",
        "  eprint={2106.04624},\n",
        "  archivePrefix={arXiv},\n",
        "  primaryClass={eess.AS},\n",
        "  note={arXiv:2106.04624}\n",
        "}"
      ],
      "metadata": {
        "id": "FqhCzkP3bzon"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}